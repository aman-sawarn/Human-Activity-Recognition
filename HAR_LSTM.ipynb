{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 85s 12ms/step - loss: 1.3786 - acc: 0.4440 - val_loss: 1.2528 - val_acc: 0.4235\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 1.0784 - acc: 0.5352 - val_loss: 1.0303 - val_acc: 0.5752\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.8563 - acc: 0.6166 - val_loss: 0.8010 - val_acc: 0.6125\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.7799 - acc: 0.6283 - val_loss: 0.8730 - val_acc: 0.5660\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.8888 - acc: 0.6026 - val_loss: 0.8774 - val_acc: 0.5996\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.8521 - acc: 0.6118 - val_loss: 0.7886 - val_acc: 0.6715\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.7086 - acc: 0.6759 - val_loss: 0.7724 - val_acc: 0.6719\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.6075 - acc: 0.7456 - val_loss: 0.6896 - val_acc: 0.7061\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.5262 - acc: 0.7967 - val_loss: 0.5552 - val_acc: 0.7954\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.4751 - acc: 0.8297 - val_loss: 0.6442 - val_acc: 0.7981\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.3885 - acc: 0.8693 - val_loss: 0.5231 - val_acc: 0.8439\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 83s 11ms/step - loss: 0.3989 - acc: 0.8723 - val_loss: 0.7403 - val_acc: 0.7978\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.3813 - acc: 0.8822 - val_loss: 0.4997 - val_acc: 0.8602\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 0.3320 - acc: 0.8976 - val_loss: 0.4645 - val_acc: 0.8649\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2989 - acc: 0.9086 - val_loss: 0.5389 - val_acc: 0.8734\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2683 - acc: 0.9174 - val_loss: 0.4436 - val_acc: 0.8877\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2839 - acc: 0.9149 - val_loss: 0.5060 - val_acc: 0.8704\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2445 - acc: 0.9191 - val_loss: 0.4943 - val_acc: 0.8748\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2361 - acc: 0.9242 - val_loss: 0.5044 - val_acc: 0.8890\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2117 - acc: 0.9340 - val_loss: 0.4618 - val_acc: 0.8968\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2076 - acc: 0.9328 - val_loss: 0.4468 - val_acc: 0.8836\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1975 - acc: 0.9380 - val_loss: 0.4910 - val_acc: 0.8839\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2053 - acc: 0.9369 - val_loss: 0.4972 - val_acc: 0.9016\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.1945 - acc: 0.9392 - val_loss: 0.5199 - val_acc: 0.8829\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2042 - acc: 0.9411 - val_loss: 0.5543 - val_acc: 0.8792\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2690 - acc: 0.9302 - val_loss: 0.5078 - val_acc: 0.8690\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2413 - acc: 0.9335 - val_loss: 0.6588 - val_acc: 0.8887\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.2039 - acc: 0.9385 - val_loss: 0.4320 - val_acc: 0.8982\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.1752 - acc: 0.9422 - val_loss: 0.4167 - val_acc: 0.8955\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.1831 - acc: 0.9430 - val_loss: 0.8186 - val_acc: 0.8724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df79ccbc18>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                 11      360        95        2                   6   \n",
      "STANDING                 0       78       448        4                   0   \n",
      "WALKING                  0        0         0      457                  33   \n",
      "WALKING_DOWNSTAIRS       0        0         0       21                 397   \n",
      "WALKING_UPSTAIRS         0        0         1       63                   8   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                           17  \n",
      "STANDING                           2  \n",
      "WALKING                            6  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 399  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 2s 824us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8186306150371352, 0.8724126230064473]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Dropout Rate and RELU Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.7))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 37s 5ms/step - loss: 1.4339 - acc: 0.4113 - val_loss: 1.2448 - val_acc: 0.4595\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.1768 - acc: 0.4890 - val_loss: 1.1081 - val_acc: 0.4903\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.0834 - acc: 0.5320 - val_loss: 1.0997 - val_acc: 0.5232\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.0673 - acc: 0.5393 - val_loss: 1.1627 - val_acc: 0.4506\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.2533 - acc: 0.4285 - val_loss: 1.2076 - val_acc: 0.3902\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.2720 - acc: 0.4165 - val_loss: 1.3062 - val_acc: 0.3831\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.2266 - acc: 0.4674 - val_loss: 1.0613 - val_acc: 0.5470\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.1429 - acc: 0.4766 - val_loss: 1.1616 - val_acc: 0.4774\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.3635 - acc: 0.3757 - val_loss: 1.2264 - val_acc: 0.4975\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.2287 - acc: 0.4180 - val_loss: 1.1451 - val_acc: 0.4863\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.1539 - acc: 0.4640 - val_loss: 1.0659 - val_acc: 0.5304\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.0689 - acc: 0.5068 - val_loss: 1.0284 - val_acc: 0.5358\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 0.9980 - acc: 0.5564 - val_loss: 1.0195 - val_acc: 0.5582\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.2918 - acc: 0.4176 - val_loss: 1.2411 - val_acc: 0.3872\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.2572 - acc: 0.4697 - val_loss: 1.1280 - val_acc: 0.5222\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.1509 - acc: 0.5177 - val_loss: 1.0379 - val_acc: 0.5412\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.0377 - acc: 0.5475 - val_loss: 0.8685 - val_acc: 0.5931\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 36s 5ms/step - loss: 0.9138 - acc: 0.5914 - val_loss: 0.8077 - val_acc: 0.6098\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.8970 - acc: 0.6088 - val_loss: 0.7578 - val_acc: 0.6152\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.8242 - acc: 0.6216 - val_loss: 0.7528 - val_acc: 0.6121\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.9144 - acc: 0.5948 - val_loss: 0.8028 - val_acc: 0.6043\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.8917 - acc: 0.6172 - val_loss: 0.7784 - val_acc: 0.6166\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.8283 - acc: 0.6269 - val_loss: 0.7544 - val_acc: 0.6549\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.8098 - acc: 0.6217 - val_loss: 0.7838 - val_acc: 0.6125\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.7904 - acc: 0.6340 - val_loss: 0.7822 - val_acc: 0.6471\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.7553 - acc: 0.6374 - val_loss: 0.7391 - val_acc: 0.6189\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.7310 - acc: 0.6517 - val_loss: 0.7317 - val_acc: 0.6271\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.7440 - acc: 0.6427 - val_loss: 0.7538 - val_acc: 0.6291\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.7409 - acc: 0.6479 - val_loss: 0.7095 - val_acc: 0.6552\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.7249 - acc: 0.6513 - val_loss: 0.7420 - val_acc: 0.6403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211924fa470>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_UPSTAIRS\n",
      "True                                                                    \n",
      "LAYING                 532        0         0        5                 0\n",
      "SITTING                  0      369       116        6                 0\n",
      "STANDING                 1       88       427       13                 3\n",
      "WALKING                  0        0         2      463                31\n",
      "WALKING_DOWNSTAIRS       2        0         1      343                74\n",
      "WALKING_UPSTAIRS         0        0         2      373                96\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less Dropout Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.3))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 83s 11ms/step - loss: 1.2783 - acc: 0.4527 - val_loss: 1.0790 - val_acc: 0.5314\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.8672 - acc: 0.6559 - val_loss: 0.8655 - val_acc: 0.6400\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.7116 - acc: 0.7038 - val_loss: 0.7483 - val_acc: 0.6807\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.6267 - acc: 0.7231 - val_loss: 0.7348 - val_acc: 0.7017\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.5954 - acc: 0.7458 - val_loss: 0.7752 - val_acc: 0.6756\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.5434 - acc: 0.7816 - val_loss: 0.7116 - val_acc: 0.7078\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.4661 - acc: 0.8137 - val_loss: 0.6520 - val_acc: 0.7421\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.4418 - acc: 0.8441 - val_loss: 0.6268 - val_acc: 0.7862\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.3919 - acc: 0.8713 - val_loss: 0.4597 - val_acc: 0.8487\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.3156 - acc: 0.9022 - val_loss: 0.5969 - val_acc: 0.8171\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.3534 - acc: 0.8949 - val_loss: 0.5798 - val_acc: 0.8266\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2926 - acc: 0.9085 - val_loss: 0.5626 - val_acc: 0.8242\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2251 - acc: 0.9290 - val_loss: 0.5247 - val_acc: 0.8548\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2352 - acc: 0.9276 - val_loss: 0.4574 - val_acc: 0.8755\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.2153 - acc: 0.9271 - val_loss: 0.5216 - val_acc: 0.8514\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.2134 - acc: 0.9308 - val_loss: 0.5099 - val_acc: 0.8751\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1950 - acc: 0.9354 - val_loss: 0.6479 - val_acc: 0.8168\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1733 - acc: 0.9382 - val_loss: 0.3539 - val_acc: 0.8890\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1606 - acc: 0.9442 - val_loss: 0.4452 - val_acc: 0.8938\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1745 - acc: 0.9411 - val_loss: 0.4392 - val_acc: 0.8924\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1755 - acc: 0.9430 - val_loss: 0.3664 - val_acc: 0.9023\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1589 - acc: 0.9430 - val_loss: 0.3396 - val_acc: 0.9046\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1541 - acc: 0.9484 - val_loss: 0.3806 - val_acc: 0.9006\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1540 - acc: 0.9463 - val_loss: 0.6425 - val_acc: 0.8748\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.1402 - acc: 0.9489 - val_loss: 0.7955 - val_acc: 0.8500\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.2104 - acc: 0.9347 - val_loss: 0.4306 - val_acc: 0.8826\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 80s 11ms/step - loss: 0.1581 - acc: 0.9430 - val_loss: 0.4077 - val_acc: 0.8975\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1603 - acc: 0.9455 - val_loss: 0.4151 - val_acc: 0.9030\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1578 - acc: 0.9476 - val_loss: 0.3542 - val_acc: 0.8985\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.1457 - acc: 0.9465 - val_loss: 0.4165 - val_acc: 0.8972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2119bda1128>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0        27        0                   0   \n",
      "SITTING                  1      389        98        1                   0   \n",
      "STANDING                 0       84       448        0                   0   \n",
      "WALKING                  0        0         0      491                   5   \n",
      "WALKING_DOWNSTAIRS       0        0         0        8                 407   \n",
      "WALKING_UPSTAIRS         0        0         5       42                  25   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 5  \n",
      "WALKING_UPSTAIRS                 399  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 128, 48)           11136     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128, 48)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 32)                10368     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 21,702\n",
      "Trainable params: 21,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(48, input_shape=(timesteps, input_dim), return_sequences=True))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(32))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 173s 24ms/step - loss: 1.0254 - acc: 0.5683 - val_loss: 0.8267 - val_acc: 0.6440\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 168s 23ms/step - loss: 0.6917 - acc: 0.6812 - val_loss: 0.8010 - val_acc: 0.6590\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 166s 23ms/step - loss: 0.4841 - acc: 0.8164 - val_loss: 0.5118 - val_acc: 0.8195\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 168s 23ms/step - loss: 0.3006 - acc: 0.9030 - val_loss: 0.4843 - val_acc: 0.8398\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1959 - acc: 0.9325 - val_loss: 0.3837 - val_acc: 0.8741\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1873 - acc: 0.9368 - val_loss: 0.3566 - val_acc: 0.8962\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1600 - acc: 0.9433 - val_loss: 0.3318 - val_acc: 0.8951\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 168s 23ms/step - loss: 0.1523 - acc: 0.9429 - val_loss: 0.4128 - val_acc: 0.8945\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1415 - acc: 0.9470 - val_loss: 0.3407 - val_acc: 0.9053\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1491 - acc: 0.9460 - val_loss: 0.3553 - val_acc: 0.9019\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1349 - acc: 0.9493 - val_loss: 0.4260 - val_acc: 0.8846\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 168s 23ms/step - loss: 0.1348 - acc: 0.9493 - val_loss: 0.2508 - val_acc: 0.9267\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1357 - acc: 0.9478 - val_loss: 0.2705 - val_acc: 0.9094\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1361 - acc: 0.9494 - val_loss: 0.2860 - val_acc: 0.9023\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1290 - acc: 0.9490 - val_loss: 0.4935 - val_acc: 0.8856\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1467 - acc: 0.9452 - val_loss: 0.3765 - val_acc: 0.9080\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1265 - acc: 0.9531 - val_loss: 0.2494 - val_acc: 0.9291\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1351 - acc: 0.9501 - val_loss: 0.3125 - val_acc: 0.8870\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1223 - acc: 0.9516 - val_loss: 0.2678 - val_acc: 0.9108\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1304 - acc: 0.9484 - val_loss: 0.2803 - val_acc: 0.9091\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1278 - acc: 0.9498 - val_loss: 0.2529 - val_acc: 0.9162\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1166 - acc: 0.9505 - val_loss: 0.2882 - val_acc: 0.9243\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1096 - acc: 0.9555 - val_loss: 0.3015 - val_acc: 0.9179\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 166s 23ms/step - loss: 0.1086 - acc: 0.9547 - val_loss: 0.2786 - val_acc: 0.9199\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 166s 23ms/step - loss: 0.1224 - acc: 0.9523 - val_loss: 0.3382 - val_acc: 0.9101\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1303 - acc: 0.9505 - val_loss: 0.2955 - val_acc: 0.9053\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 166s 23ms/step - loss: 0.1194 - acc: 0.9533 - val_loss: 0.3555 - val_acc: 0.9002\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 166s 23ms/step - loss: 0.1203 - acc: 0.9517 - val_loss: 0.2885 - val_acc: 0.9189\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 167s 23ms/step - loss: 0.1222 - acc: 0.9514 - val_loss: 0.3458 - val_acc: 0.8982\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 166s 23ms/step - loss: 0.1089 - acc: 0.9548 - val_loss: 0.3356 - val_acc: 0.8945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211a1faaef0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  5      281       203        0                   1   \n",
      "STANDING                 0       33       496        3                   0   \n",
      "WALKING                  0        0         1      465                  16   \n",
      "WALKING_DOWNSTAIRS       0        0         0        4                 406   \n",
      "WALKING_UPSTAIRS         0        0         2       12                   6   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            1  \n",
      "STANDING                           0  \n",
      "WALKING                           14  \n",
      "WALKING_DOWNSTAIRS                10  \n",
      "WALKING_UPSTAIRS                 451  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, MaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling3D, Embedding, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 124, 64)           34624     \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 122, 100)          19300     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 120, 100)          30100     \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 118, 48)           14448     \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 5664)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 6)                 33990     \n",
      "=================================================================\n",
      "Total params: 137,502\n",
      "Trainable params: 137,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='sigmoid'))\n",
    "# model.add(Dropout(0.70))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Conv1D(48, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 58s 8ms/step - loss: 0.7124 - acc: 0.6748 - val_loss: 0.5101 - val_acc: 0.7889\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.3312 - acc: 0.8848 - val_loss: 0.6078 - val_acc: 0.8595\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1751 - acc: 0.9306 - val_loss: 0.5268 - val_acc: 0.8860\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1730 - acc: 0.9338 - val_loss: 0.6330 - val_acc: 0.8714\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1547 - acc: 0.9404 - val_loss: 0.5233 - val_acc: 0.8870\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1311 - acc: 0.9465 - val_loss: 0.5823 - val_acc: 0.8887\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1189 - acc: 0.9490 - val_loss: 0.4969 - val_acc: 0.8982\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 54s 7ms/step - loss: 0.1236 - acc: 0.9455 - val_loss: 0.5703 - val_acc: 0.8985\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1199 - acc: 0.9501 - val_loss: 0.5967 - val_acc: 0.9013\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1172 - acc: 0.9508 - val_loss: 0.6263 - val_acc: 0.8955\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 1.4949 - acc: 0.8505 - val_loss: 0.7478 - val_acc: 0.8351\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1688 - acc: 0.9442 - val_loss: 0.4698 - val_acc: 0.8982\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1203 - acc: 0.9513 - val_loss: 0.4480 - val_acc: 0.8890\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1080 - acc: 0.9531 - val_loss: 0.4569 - val_acc: 0.9013\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 53s 7ms/step - loss: 0.1073 - acc: 0.9532 - val_loss: 0.4379 - val_acc: 0.9006\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1182 - acc: 0.9508 - val_loss: 0.6934 - val_acc: 0.8704\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1180 - acc: 0.9495 - val_loss: 0.4300 - val_acc: 0.9091\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1075 - acc: 0.9510 - val_loss: 0.4925 - val_acc: 0.9046\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1205 - acc: 0.9501 - val_loss: 0.6333 - val_acc: 0.8843\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1146 - acc: 0.9527 - val_loss: 0.5574 - val_acc: 0.9026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df2f68c4a8>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential()\n",
    "# model.add(Conv2D(64, kernel_size=(5, 5),activation='relu', padding='same', input_shape=(timesteps, input_dim))) \n",
    "# model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides = 2)) \n",
    "# model.add(Dropout(0.5)) \n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', padding='same')) \n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides = 2)) \n",
    "# model.add(BatchNormalization()) \n",
    "# model.add(Dropout(0.5)) \n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(100, activation='relu')) \n",
    "# model.add(BatchNormalization()) \n",
    "# model.add(Dropout(0.5)) \n",
    "# model.add(Dense(n_classes, activation='softmax')) \n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compiling the model\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Training the model\n",
    "# model.fit(X_train,\n",
    "#           Y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           validation_data=(X_test, Y_test),\n",
    "#           epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      403        60        0                   0   \n",
      "STANDING                 0       96       434        0                   0   \n",
      "WALKING                  0        0         0      492                   2   \n",
      "WALKING_DOWNSTAIRS       0        0         0        7                 386   \n",
      "WALKING_UPSTAIRS         0        0         0       14                  22   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                           28  \n",
      "STANDING                           2  \n",
      "WALKING                            2  \n",
      "WALKING_DOWNSTAIRS                27  \n",
      "WALKING_UPSTAIRS                 435  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_111 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 124, 64)           34624     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 122, 100)          19300     \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 120, 100)          30100     \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 120, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 118, 48)           14448     \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 5664)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 6)                 33990     \n",
      "=================================================================\n",
      "Total params: 137,502\n",
      "Trainable params: 137,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='sigmoid'))\n",
    "\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(48, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.8332 - acc: 0.6239 - val_loss: 0.6980 - val_acc: 0.7621\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.3117 - acc: 0.8837 - val_loss: 0.6173 - val_acc: 0.8422\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.2038 - acc: 0.9211 - val_loss: 0.4948 - val_acc: 0.8751\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.2018 - acc: 0.9289 - val_loss: 0.4100 - val_acc: 0.8843\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1477 - acc: 0.9416 - val_loss: 0.4456 - val_acc: 0.9118\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1403 - acc: 0.9418 - val_loss: 0.3199 - val_acc: 0.9131\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1455 - acc: 0.9376 - val_loss: 0.3042 - val_acc: 0.9199\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1129 - acc: 0.9518 - val_loss: 0.3259 - val_acc: 0.8968\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1101 - acc: 0.9561 - val_loss: 0.3315 - val_acc: 0.9101\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1388 - acc: 0.9434 - val_loss: 0.4665 - val_acc: 0.8890\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1059 - acc: 0.9531 - val_loss: 0.5494 - val_acc: 0.8653\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1526 - acc: 0.9452 - val_loss: 0.4744 - val_acc: 0.9030\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1034 - acc: 0.9555 - val_loss: 0.4669 - val_acc: 0.9104\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1019 - acc: 0.9539 - val_loss: 0.4674 - val_acc: 0.9141\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1793 - acc: 0.9418 - val_loss: 0.4558 - val_acc: 0.9019\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1017 - acc: 0.9551 - val_loss: 0.4555 - val_acc: 0.8829\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.0993 - acc: 0.9562 - val_loss: 0.5472 - val_acc: 0.9013\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1262 - acc: 0.9486 - val_loss: 0.4889 - val_acc: 0.9009\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.0903 - acc: 0.9565 - val_loss: 0.5739 - val_acc: 0.9040\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 59s 8ms/step - loss: 0.1019 - acc: 0.9542 - val_loss: 0.3409 - val_acc: 0.9220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df31e8e5c0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      424        63        1                   1   \n",
      "STANDING                 0      106       426        0                   0   \n",
      "WALKING                  0        0         0      471                   4   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 414   \n",
      "WALKING_UPSTAIRS         0        0         0        4                  22   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                           21  \n",
      "WALKING_DOWNSTAIRS                 5  \n",
      "WALKING_UPSTAIRS                 445  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_119 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 124, 64)           34624     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 122, 100)          19300     \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 122, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 120, 100)          30100     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 120, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 118, 48)           14448     \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 5664)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 6)                 33990     \n",
      "=================================================================\n",
      "Total params: 137,502\n",
      "Trainable params: 137,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='sigmoid'))\n",
    "\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(48, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 1.0805 - acc: 0.5041 - val_loss: 0.6758 - val_acc: 0.7116\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 57s 8ms/step - loss: 0.5067 - acc: 0.7654 - val_loss: 1.3113 - val_acc: 0.5653\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.3559 - acc: 0.8644 - val_loss: 0.6839 - val_acc: 0.7109\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2556 - acc: 0.9066 - val_loss: 0.7907 - val_acc: 0.7245\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.2374 - acc: 0.9113 - val_loss: 0.8164 - val_acc: 0.7462\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.2084 - acc: 0.9207 - val_loss: 0.7986 - val_acc: 0.6291\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1763 - acc: 0.9320 - val_loss: 0.9645 - val_acc: 0.6580\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1690 - acc: 0.9339 - val_loss: 1.0571 - val_acc: 0.6956\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1606 - acc: 0.9362 - val_loss: 0.7097 - val_acc: 0.7431\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1510 - acc: 0.9408 - val_loss: 0.6048 - val_acc: 0.7835\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1435 - acc: 0.9404 - val_loss: 0.7669 - val_acc: 0.7357\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1488 - acc: 0.9418 - val_loss: 0.9152 - val_acc: 0.6990\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1415 - acc: 0.9423 - val_loss: 0.8276 - val_acc: 0.7000\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.2615 - acc: 0.9369 - val_loss: 0.4686 - val_acc: 0.8249\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1645 - acc: 0.9455 - val_loss: 0.6812 - val_acc: 0.7574\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1643 - acc: 0.9431 - val_loss: 0.5850 - val_acc: 0.7418\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1597 - acc: 0.9470 - val_loss: 0.9420 - val_acc: 0.7000\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1480 - acc: 0.9491 - val_loss: 1.3577 - val_acc: 0.6742\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1607 - acc: 0.9433 - val_loss: 0.8432 - val_acc: 0.7055\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1514 - acc: 0.9489 - val_loss: 1.0572 - val_acc: 0.6715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df55ab9a58>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 518        0        19        0                   0   \n",
      "SITTING                  0      154       328        0                   4   \n",
      "STANDING                 0        0       525        0                   0   \n",
      "WALKING                  0        0         0       23                 379   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         0        0         0        0                 132   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            5  \n",
      "STANDING                           7  \n",
      "WALKING                           94  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 339  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 124, 128)          69248     \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 122, 64)           24640     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 122, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 120, 100)          19300     \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 120, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 118, 100)          30100     \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 118, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 116, 48)           14448     \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 5568)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 6)                 33414     \n",
      "=================================================================\n",
      "Total params: 196,190\n",
      "Trainable params: 196,190\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='sigmoid'))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Conv1D(100, 3, activation='sigmoid'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(48, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/20\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 1.4955 - acc: 0.3467 - val_loss: 0.7858 - val_acc: 0.5999\n",
      "Epoch 2/20\n",
      "7352/7352 [==============================] - 89s 12ms/step - loss: 0.6623 - acc: 0.6797 - val_loss: 0.6423 - val_acc: 0.7621\n",
      "Epoch 3/20\n",
      "7352/7352 [==============================] - 95s 13ms/step - loss: 0.4233 - acc: 0.8236 - val_loss: 0.4580 - val_acc: 0.8297\n",
      "Epoch 4/20\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2981 - acc: 0.8844 - val_loss: 0.4995 - val_acc: 0.8045\n",
      "Epoch 5/20\n",
      "7352/7352 [==============================] - 94s 13ms/step - loss: 0.2476 - acc: 0.9051 - val_loss: 0.4902 - val_acc: 0.8551\n",
      "Epoch 6/20\n",
      "7352/7352 [==============================] - 93s 13ms/step - loss: 0.2052 - acc: 0.9188 - val_loss: 0.4677 - val_acc: 0.8476\n",
      "Epoch 7/20\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.2146 - acc: 0.9236 - val_loss: 0.5333 - val_acc: 0.8531\n",
      "Epoch 8/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1752 - acc: 0.9335 - val_loss: 0.5538 - val_acc: 0.8673\n",
      "Epoch 9/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1739 - acc: 0.9321 - val_loss: 0.5765 - val_acc: 0.8290\n",
      "Epoch 10/20\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1493 - acc: 0.9373 - val_loss: 0.5415 - val_acc: 0.8707\n",
      "Epoch 11/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1353 - acc: 0.9433 - val_loss: 1.0159 - val_acc: 0.8045\n",
      "Epoch 12/20\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1469 - acc: 0.9408 - val_loss: 0.5050 - val_acc: 0.8782\n",
      "Epoch 13/20\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1445 - acc: 0.9403 - val_loss: 0.4948 - val_acc: 0.8836\n",
      "Epoch 14/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1369 - acc: 0.9408 - val_loss: 0.8393 - val_acc: 0.8062\n",
      "Epoch 15/20\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1498 - acc: 0.9378 - val_loss: 0.7289 - val_acc: 0.8744\n",
      "Epoch 16/20\n",
      "7352/7352 [==============================] - 50s 7ms/step - loss: 0.1492 - acc: 0.9444 - val_loss: 0.5397 - val_acc: 0.8826\n",
      "Epoch 17/20\n",
      "7352/7352 [==============================] - 52s 7ms/step - loss: 0.1679 - acc: 0.9421 - val_loss: 0.7785 - val_acc: 0.8751\n",
      "Epoch 18/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1521 - acc: 0.9474 - val_loss: 0.7445 - val_acc: 0.8704\n",
      "Epoch 19/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1549 - acc: 0.9444 - val_loss: 0.7448 - val_acc: 0.8470\n",
      "Epoch 20/20\n",
      "7352/7352 [==============================] - 51s 7ms/step - loss: 0.1473 - acc: 0.9482 - val_loss: 0.6529 - val_acc: 0.8880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df55cf2710>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 509        0         0        3                  25   \n",
      "SITTING                  0      428        53        4                   3   \n",
      "STANDING                 0      115       417        0                   0   \n",
      "WALKING                  0        0         0      411                   9   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 408   \n",
      "WALKING_UPSTAIRS         0        0         0        1                  26   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            3  \n",
      "STANDING                           0  \n",
      "WALKING                           76  \n",
      "WALKING_DOWNSTAIRS                12  \n",
      "WALKING_UPSTAIRS                 444  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_258 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "conv1d_259 (Conv1D)          (None, 124, 64)           34624     \n",
      "_________________________________________________________________\n",
      "conv1d_260 (Conv1D)          (None, 122, 100)          19300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 122, 100)          400       \n",
      "_________________________________________________________________\n",
      "conv1d_261 (Conv1D)          (None, 120, 100)          30100     \n",
      "_________________________________________________________________\n",
      "dropout_167 (Dropout)        (None, 120, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_262 (Conv1D)          (None, 118, 48)           14448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 118, 48)           192       \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 5664)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 6)                 33990     \n",
      "=================================================================\n",
      "Total params: 138,094\n",
      "Trainable params: 137,798\n",
      "Non-trainable params: 296\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='sigmoid'))\n",
    "\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(48, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/25\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.5258 - acc: 0.8183 - val_loss: 4.0344 - val_acc: 0.5103\n",
      "Epoch 2/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.3225 - acc: 0.8973 - val_loss: 9.8705 - val_acc: 0.3482\n",
      "Epoch 3/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2328 - acc: 0.9159 - val_loss: 1.4637 - val_acc: 0.6834\n",
      "Epoch 4/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2205 - acc: 0.9211 - val_loss: 1.8193 - val_acc: 0.5989\n",
      "Epoch 5/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.2224 - acc: 0.9212 - val_loss: 0.4619 - val_acc: 0.8537\n",
      "Epoch 6/25\n",
      "7352/7352 [==============================] - 49s 7ms/step - loss: 0.2087 - acc: 0.9251 - val_loss: 1.0139 - val_acc: 0.7672\n",
      "Epoch 7/25\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 0.1769 - acc: 0.9328 - val_loss: 1.1607 - val_acc: 0.7326\n",
      "Epoch 8/25\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1981 - acc: 0.9257 - val_loss: 0.5293 - val_acc: 0.8690\n",
      "Epoch 9/25\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.2023 - acc: 0.9325 - val_loss: 1.0309 - val_acc: 0.7682\n",
      "Epoch 10/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1908 - acc: 0.9321 - val_loss: 0.6024 - val_acc: 0.8191\n",
      "Epoch 11/25\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1664 - acc: 0.9346 - val_loss: 0.8617 - val_acc: 0.7462\n",
      "Epoch 12/25\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1749 - acc: 0.9338 - val_loss: 0.7117 - val_acc: 0.8534\n",
      "Epoch 13/25\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1806 - acc: 0.9362 - val_loss: 0.4761 - val_acc: 0.8935\n",
      "Epoch 14/25\n",
      "7352/7352 [==============================] - 42s 6ms/step - loss: 0.1468 - acc: 0.9442 - val_loss: 0.5336 - val_acc: 0.7896\n",
      "Epoch 15/25\n",
      "7352/7352 [==============================] - 43s 6ms/step - loss: 0.1527 - acc: 0.9397 - val_loss: 1.2164 - val_acc: 0.6912\n",
      "Epoch 16/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1427 - acc: 0.9429 - val_loss: 0.7362 - val_acc: 0.8012\n",
      "Epoch 17/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1762 - acc: 0.9355 - val_loss: 0.3750 - val_acc: 0.8982764 - acc: 0.935\n",
      "Epoch 18/25\n",
      "7352/7352 [==============================] - 44s 6ms/step - loss: 0.1360 - acc: 0.9431 - val_loss: 0.9914 - val_acc: 0.7072\n",
      "Epoch 19/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1488 - acc: 0.9445 - val_loss: 1.3637 - val_acc: 0.6882\n",
      "Epoch 20/25\n",
      "7352/7352 [==============================] - 45s 6ms/step - loss: 0.1475 - acc: 0.9425 - val_loss: 1.7007 - val_acc: 0.6627\n",
      "Epoch 21/25\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1538 - acc: 0.9410 - val_loss: 0.6813 - val_acc: 0.8259\n",
      "Epoch 22/25\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1456 - acc: 0.9453 - val_loss: 0.9137 - val_acc: 0.7323\n",
      "Epoch 23/25\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1473 - acc: 0.9431 - val_loss: 0.9294 - val_acc: 0.7357\n",
      "Epoch 24/25\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.1377 - acc: 0.9437 - val_loss: 1.7281 - val_acc: 0.7343\n",
      "Epoch 25/25\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1407 - acc: 0.9442 - val_loss: 1.4099 - val_acc: 0.7414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dfb9ddf4e0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                  27      239       271        0                   0   \n",
      "SITTING                  0      430        40        0                   0   \n",
      "STANDING                 0      135       396        0                   0   \n",
      "WALKING                  0        1         1      476                  18   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 419   \n",
      "WALKING_UPSTAIRS         0        8         1        1                  24   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                           21  \n",
      "STANDING                           1  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 1  \n",
      "WALKING_UPSTAIRS                 437  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_263 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "conv1d_264 (Conv1D)          (None, 124, 64)           34624     \n",
      "_________________________________________________________________\n",
      "conv1d_265 (Conv1D)          (None, 122, 100)          19300     \n",
      "_________________________________________________________________\n",
      "conv1d_266 (Conv1D)          (None, 120, 100)          30100     \n",
      "_________________________________________________________________\n",
      "dropout_168 (Dropout)        (None, 120, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_267 (Conv1D)          (None, 118, 48)           14448     \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 5664)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 6)                 33990     \n",
      "=================================================================\n",
      "Total params: 137,502\n",
      "Trainable params: 137,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='sigmoid'))\n",
    "\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(48, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 79s 11ms/step - loss: 0.8301 - acc: 0.6137 - val_loss: 0.6556 - val_acc: 0.7095\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.3570 - acc: 0.8569 - val_loss: 0.7334 - val_acc: 0.8195\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.2380 - acc: 0.9097 - val_loss: 0.6728 - val_acc: 0.8527\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.2183 - acc: 0.9222 - val_loss: 0.6101 - val_acc: 0.8456\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1811 - acc: 0.9323 - val_loss: 0.4502 - val_acc: 0.8778\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1447 - acc: 0.9429 - val_loss: 0.7354 - val_acc: 0.8178\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1519 - acc: 0.9400 - val_loss: 0.3219 - val_acc: 0.8989\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1266 - acc: 0.9452 - val_loss: 0.3821 - val_acc: 0.9026\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1227 - acc: 0.9479 - val_loss: 0.3401 - val_acc: 0.9026\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1248 - acc: 0.9506 - val_loss: 0.5230 - val_acc: 0.8755\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.2472 - acc: 0.9272 - val_loss: 0.5149 - val_acc: 0.8918\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1695 - acc: 0.9463 - val_loss: 0.5773 - val_acc: 0.8999\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1451 - acc: 0.9498 - val_loss: 0.6002 - val_acc: 0.8965\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 66s 9ms/step - loss: 0.1479 - acc: 0.9499 - val_loss: 0.7571 - val_acc: 0.8551\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.2380 - acc: 0.9387 - val_loss: 0.6039 - val_acc: 0.9002\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1090 - acc: 0.9540 - val_loss: 0.5493 - val_acc: 0.9033\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.1054 - acc: 0.9524 - val_loss: 0.5249 - val_acc: 0.8962\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1258 - acc: 0.9484 - val_loss: 0.5267 - val_acc: 0.8972\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 67s 9ms/step - loss: 0.1189 - acc: 0.9495 - val_loss: 0.9721 - val_acc: 0.8775\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1635 - acc: 0.9489 - val_loss: 0.6451 - val_acc: 0.8989\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1503 - acc: 0.9487 - val_loss: 0.6667 - val_acc: 0.8982\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1362 - acc: 0.9509 - val_loss: 0.6595 - val_acc: 0.9074\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 60s 8ms/step - loss: 0.1382 - acc: 0.9504 - val_loss: 0.5123 - val_acc: 0.9033\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1438 - acc: 0.9508 - val_loss: 0.5734 - val_acc: 0.9036\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1649 - acc: 0.9493 - val_loss: 0.5595 - val_acc: 0.8921\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1684 - acc: 0.9487 - val_loss: 0.5168 - val_acc: 0.9013\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1012 - acc: 0.9557 - val_loss: 0.5749 - val_acc: 0.9141\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1018 - acc: 0.9533 - val_loss: 0.4477 - val_acc: 0.9101\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.0949 - acc: 0.9569 - val_loss: 0.4841 - val_acc: 0.9046\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.0963 - acc: 0.9587 - val_loss: 0.4914 - val_acc: 0.9104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dfc11cc908>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0       24                   0   \n",
      "SITTING                  0      417        68        0                   6   \n",
      "STANDING                 0      103       429        0                   0   \n",
      "WALKING                  0        0         0      474                  21   \n",
      "WALKING_DOWNSTAIRS       0        0         0        2                 418   \n",
      "WALKING_UPSTAIRS         0        0         0        0                  36   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             3  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 435  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_333 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "dropout_216 (Dropout)        (None, 126, 180)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_334 (Conv1D)          (None, 124, 128)          69248     \n",
      "_________________________________________________________________\n",
      "dropout_217 (Dropout)        (None, 124, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_335 (Conv1D)          (None, 122, 100)          38500     \n",
      "_________________________________________________________________\n",
      "dropout_218 (Dropout)        (None, 122, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_336 (Conv1D)          (None, 120, 64)           19264     \n",
      "_________________________________________________________________\n",
      "dropout_219 (Dropout)        (None, 120, 64)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 120, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_337 (Conv1D)          (None, 118, 48)           9264      \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 5664)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 6)                 33990     \n",
      "=================================================================\n",
      "Total params: 175,562\n",
      "Trainable params: 175,434\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(128, 3, activation='sigmoid'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(48, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 119s 16ms/step - loss: 1.6252 - acc: 0.3400 - val_loss: 1.9785 - val_acc: 0.3325\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.8570 - acc: 0.5813 - val_loss: 0.9543 - val_acc: 0.5969\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.6203 - acc: 0.7160 - val_loss: 0.9646 - val_acc: 0.6016\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.4261 - acc: 0.8317 - val_loss: 1.1107 - val_acc: 0.6600\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.3186 - acc: 0.8838 - val_loss: 0.8718 - val_acc: 0.7533\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.2743 - acc: 0.8979 - val_loss: 1.0316 - val_acc: 0.7357\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.2301 - acc: 0.9123 - val_loss: 0.7011 - val_acc: 0.8202\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.2060 - acc: 0.9184 - val_loss: 0.6063 - val_acc: 0.8453\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 105s 14ms/step - loss: 0.1900 - acc: 0.9280 - val_loss: 0.7452 - val_acc: 0.8269\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.1823 - acc: 0.9308 - val_loss: 0.5892 - val_acc: 0.8514\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1650 - acc: 0.9353 - val_loss: 0.8592 - val_acc: 0.8100\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.1707 - acc: 0.9359 - val_loss: 0.9489 - val_acc: 0.7886\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1573 - acc: 0.9369 - val_loss: 0.5675 - val_acc: 0.8666\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1637 - acc: 0.9365 - val_loss: 0.7529 - val_acc: 0.8388\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1552 - acc: 0.9380 - val_loss: 0.4624 - val_acc: 0.8958\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1477 - acc: 0.9402 - val_loss: 0.5695 - val_acc: 0.8782\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1454 - acc: 0.9441 - val_loss: 0.7895 - val_acc: 0.8568\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1441 - acc: 0.9422 - val_loss: 0.6113 - val_acc: 0.8653\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1366 - acc: 0.9464 - val_loss: 0.7183 - val_acc: 0.8554\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1568 - acc: 0.9395 - val_loss: 0.5429 - val_acc: 0.8755\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.1585 - acc: 0.9407 - val_loss: 0.6083 - val_acc: 0.8789\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 103s 14ms/step - loss: 0.1239 - acc: 0.9453 - val_loss: 0.5657 - val_acc: 0.8982\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 102s 14ms/step - loss: 0.1269 - acc: 0.9484 - val_loss: 0.8070 - val_acc: 0.8673\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 104s 14ms/step - loss: 0.1234 - acc: 0.9449 - val_loss: 0.6718 - val_acc: 0.8928\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.1308 - acc: 0.9446 - val_loss: 0.5349 - val_acc: 0.8833\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.1429 - acc: 0.9411 - val_loss: 0.6550 - val_acc: 0.8741\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 107s 15ms/step - loss: 0.1147 - acc: 0.9489 - val_loss: 0.5484 - val_acc: 0.9091\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 107s 15ms/step - loss: 0.1211 - acc: 0.9453 - val_loss: 0.6197 - val_acc: 0.8921\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 107s 15ms/step - loss: 0.1097 - acc: 0.9524 - val_loss: 0.5560 - val_acc: 0.9080\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 106s 14ms/step - loss: 0.1129 - acc: 0.9517 - val_loss: 0.5920 - val_acc: 0.9006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e01ce96320>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      440        40        0                   3   \n",
      "STANDING                 0      136       394        0                   0   \n",
      "WALKING                  0        1         0      425                  58   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         0        2         0        0                  31   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            8  \n",
      "STANDING                           2  \n",
      "WALKING                           12  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 438  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_338 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "dropout_220 (Dropout)        (None, 126, 180)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_339 (Conv1D)          (None, 124, 128)          69248     \n",
      "_________________________________________________________________\n",
      "dropout_221 (Dropout)        (None, 124, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_340 (Conv1D)          (None, 122, 100)          38500     \n",
      "_________________________________________________________________\n",
      "dropout_222 (Dropout)        (None, 122, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_341 (Conv1D)          (None, 120, 64)           19264     \n",
      "_________________________________________________________________\n",
      "dropout_223 (Dropout)        (None, 120, 64)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 120, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_342 (Conv1D)          (None, 118, 48)           9264      \n",
      "_________________________________________________________________\n",
      "flatten_54 (Flatten)         (None, 5664)              0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 6)                 33990     \n",
      "=================================================================\n",
      "Total params: 175,562\n",
      "Trainable params: 175,434\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(48, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 125s 17ms/step - loss: 1.1485 - acc: 0.5635 - val_loss: 4.5156 - val_acc: 0.3739\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 110s 15ms/step - loss: 0.6023 - acc: 0.7745 - val_loss: 2.3681 - val_acc: 0.4808\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 110s 15ms/step - loss: 0.4101 - acc: 0.8444 - val_loss: 1.2354 - val_acc: 0.6376\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 109s 15ms/step - loss: 0.3293 - acc: 0.8720 - val_loss: 0.9711 - val_acc: 0.6922\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 109s 15ms/step - loss: 0.2608 - acc: 0.9032 - val_loss: 0.9502 - val_acc: 0.6780\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 109s 15ms/step - loss: 0.2068 - acc: 0.9189 - val_loss: 1.2295 - val_acc: 0.7000\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 110s 15ms/step - loss: 0.1975 - acc: 0.9248 - val_loss: 0.7095 - val_acc: 0.8385\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 110s 15ms/step - loss: 0.1586 - acc: 0.9365 - val_loss: 0.7568 - val_acc: 0.7669\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 110s 15ms/step - loss: 0.1575 - acc: 0.9380 - val_loss: 0.5579 - val_acc: 0.8806\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 110s 15ms/step - loss: 0.1677 - acc: 0.9348 - val_loss: 0.6781 - val_acc: 0.8833\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 114s 16ms/step - loss: 0.1633 - acc: 0.9366 - val_loss: 0.4130 - val_acc: 0.8972\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 115s 16ms/step - loss: 0.1577 - acc: 0.9404 - val_loss: 0.5655 - val_acc: 0.8707\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 116s 16ms/step - loss: 0.1471 - acc: 0.9414 - val_loss: 0.3516 - val_acc: 0.9138\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 116s 16ms/step - loss: 0.1236 - acc: 0.9463 - val_loss: 0.5816 - val_acc: 0.8853\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 116s 16ms/step - loss: 0.1417 - acc: 0.9449 - val_loss: 0.6912 - val_acc: 0.8649\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.1325 - acc: 0.9467 - val_loss: 0.5312 - val_acc: 0.8677\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 116s 16ms/step - loss: 0.1378 - acc: 0.9490 - val_loss: 0.5955 - val_acc: 0.8439\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 117s 16ms/step - loss: 0.1319 - acc: 0.9468 - val_loss: 0.7737 - val_acc: 0.8985\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 116s 16ms/step - loss: 0.1114 - acc: 0.9518 - val_loss: 0.7149 - val_acc: 0.8802\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 25229s 3s/step - loss: 0.1160 - acc: 0.9509 - val_loss: 0.7079 - val_acc: 0.8724\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.1383 - acc: 0.9476 - val_loss: 0.7249 - val_acc: 0.8829\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 61s 8ms/step - loss: 0.1211 - acc: 0.9506 - val_loss: 0.6499 - val_acc: 0.8738\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 64s 9ms/step - loss: 0.1168 - acc: 0.9516 - val_loss: 0.5623 - val_acc: 0.8758\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 65s 9ms/step - loss: 0.1116 - acc: 0.9548 - val_loss: 0.7377 - val_acc: 0.8846\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1267 - acc: 0.9536 - val_loss: 0.7561 - val_acc: 0.8497\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.1117 - acc: 0.9508 - val_loss: 0.7761 - val_acc: 0.8809\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.1152 - acc: 0.9523 - val_loss: 0.6757 - val_acc: 0.8741\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1035 - acc: 0.9536 - val_loss: 0.8226 - val_acc: 0.8765\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.0998 - acc: 0.9562 - val_loss: 0.7732 - val_acc: 0.8721\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.1141 - acc: 0.9536 - val_loss: 0.6179 - val_acc: 0.8877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e023c217b8>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      430        59        0                   0   \n",
      "STANDING                 0      174       358        0                   0   \n",
      "WALKING                  0        0         1      473                  22   \n",
      "WALKING_DOWNSTAIRS       0        0         0       13                 407   \n",
      "WALKING_UPSTAIRS         0        0         1       35                  24   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                            2  \n",
      "STANDING                           0  \n",
      "WALKING                            0  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 411  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_343 (Conv1D)          (None, 126, 180)          5040      \n",
      "_________________________________________________________________\n",
      "dropout_224 (Dropout)        (None, 126, 180)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_344 (Conv1D)          (None, 124, 128)          69248     \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 124, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_345 (Conv1D)          (None, 122, 100)          38500     \n",
      "_________________________________________________________________\n",
      "dropout_226 (Dropout)        (None, 122, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_346 (Conv1D)          (None, 120, 64)           19264     \n",
      "_________________________________________________________________\n",
      "dropout_227 (Dropout)        (None, 120, 64)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 120, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_347 (Conv1D)          (None, 118, 48)           9264      \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 5664)              0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 6)                 33990     \n",
      "=================================================================\n",
      "Total params: 175,562\n",
      "Trainable params: 175,434\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(180, 3, input_shape=(timesteps, input_dim), activation='sigmoid'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(128, 3, activation='sigmoid'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(100, 3, activation='sigmoid'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(Conv1D(64, 3, activation='sigmoid'))\n",
    "model.add(Dropout(0.70))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(48, 3, activation='sigmoid'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# model.add(Dropout(0.70))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 81s 11ms/step - loss: 2.0911 - acc: 0.1782 - val_loss: 2.0241 - val_acc: 0.1598\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 1.7430 - acc: 0.2572 - val_loss: 1.3453 - val_acc: 0.4147\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 1.1830 - acc: 0.4743 - val_loss: 1.3303 - val_acc: 0.4778\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 1.1033 - acc: 0.5146 - val_loss: 1.3857 - val_acc: 0.4720\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.8494 - acc: 0.6662 - val_loss: 0.9298 - val_acc: 0.6390\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.5539 - acc: 0.7644 - val_loss: 0.7508 - val_acc: 0.6885\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.4860 - acc: 0.7939 - val_loss: 0.4777 - val_acc: 0.8144\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.4093 - acc: 0.8350 - val_loss: 0.3864 - val_acc: 0.8351\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.3526 - acc: 0.8589 - val_loss: 0.3684 - val_acc: 0.8812\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 78s 11ms/step - loss: 0.3249 - acc: 0.8727 - val_loss: 0.4192 - val_acc: 0.8337\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.3071 - acc: 0.8811 - val_loss: 0.3881 - val_acc: 0.8402\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 68s 9ms/step - loss: 0.2884 - acc: 0.8883 - val_loss: 0.3558 - val_acc: 0.8833\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 69s 9ms/step - loss: 0.2662 - acc: 0.8904 - val_loss: 0.4069 - val_acc: 0.8412\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.2562 - acc: 0.8957 - val_loss: 0.3346 - val_acc: 0.8697\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.2386 - acc: 0.9060 - val_loss: 0.3228 - val_acc: 0.8802\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 70s 10ms/step - loss: 0.2324 - acc: 0.9071 - val_loss: 0.3664 - val_acc: 0.8588\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 71s 10ms/step - loss: 0.2242 - acc: 0.9097 - val_loss: 0.3304 - val_acc: 0.8561\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 74s 10ms/step - loss: 0.2117 - acc: 0.9125 - val_loss: 0.3271 - val_acc: 0.8829\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.2105 - acc: 0.9129 - val_loss: 0.3430 - val_acc: 0.8846\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 76s 10ms/step - loss: 0.2001 - acc: 0.9172 - val_loss: 0.3316 - val_acc: 0.8846\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1910 - acc: 0.9203 - val_loss: 0.4613 - val_acc: 0.8273\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1829 - acc: 0.9270 - val_loss: 0.4077 - val_acc: 0.8751\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1831 - acc: 0.9241 - val_loss: 0.3631 - val_acc: 0.8935\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 73s 10ms/step - loss: 0.1779 - acc: 0.9266 - val_loss: 0.3600 - val_acc: 0.8870\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1697 - acc: 0.9278 - val_loss: 0.4255 - val_acc: 0.8724\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1668 - acc: 0.9324 - val_loss: 0.4048 - val_acc: 0.8741\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 77s 10ms/step - loss: 0.1649 - acc: 0.9314 - val_loss: 0.4105 - val_acc: 0.8731\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 83s 11ms/step - loss: 0.1647 - acc: 0.9310 - val_loss: 0.3933 - val_acc: 0.8985\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 72s 10ms/step - loss: 0.1601 - acc: 0.9340 - val_loss: 0.3756 - val_acc: 0.8802\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 75s 10ms/step - loss: 0.1465 - acc: 0.9374 - val_loss: 0.3930 - val_acc: 0.8979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e03e7aa6a0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      340       151        0                   0   \n",
      "STANDING                 0       47       485        0                   0   \n",
      "WALKING                  0        0         2      466                  12   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 397   \n",
      "WALKING_UPSTAIRS         0        0         0        6                  17   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            0  \n",
      "STANDING                           0  \n",
      "WALKING                           16  \n",
      "WALKING_DOWNSTAIRS                23  \n",
      "WALKING_UPSTAIRS                 448  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_348 (Conv1D)          (None, 126, 100)          2800      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 42, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_56 (Flatten)         (None, 4200)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 6)                 25206     \n",
      "_________________________________________________________________\n",
      "dropout_228 (Dropout)        (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 28,006\n",
      "Trainable params: 28,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/heeryoncho/sensors2018cnnhar/blob/master/har/har_dyna_learn_model.py\n",
    "model = Sequential()\n",
    "model.add(Conv1D(100, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "adam = Adam(lr=0.0004, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# Summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1290 - acc: 0.4241 - val_loss: 0.0736 - val_acc: 0.7950\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1158 - acc: 0.4708 - val_loss: 0.0656 - val_acc: 0.8548\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1104 - acc: 0.4833 - val_loss: 0.0609 - val_acc: 0.8846\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1092 - acc: 0.4848 - val_loss: 0.0584 - val_acc: 0.8870\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.1074 - acc: 0.4895 - val_loss: 0.0590 - val_acc: 0.8911s - loss: 0.1084 - acc: 0.485 - ETA: 9s - l - ETA: 7s - loss: 0.108 - ETA: 6s - loss: 0.1 - ETA: 3s - loss: 0.1077 - acc: 0.487 - ETA: 3s - loss: 0.1076 - a - ETA: 0s - loss: 0.1074 - a\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 0.1073 - acc: 0.4901 - val_loss: 0.0588 - val_acc: 0.8965\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1069 - acc: 0.4882 - val_loss: 0.0565 - val_acc: 0.8931\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1077 - acc: 0.4811 - val_loss: 0.0555 - val_acc: 0.8968\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1057 - acc: 0.4954 - val_loss: 0.0563 - val_acc: 0.9013\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1057 - acc: 0.4933 - val_loss: 0.0565 - val_acc: 0.9101\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1064 - acc: 0.4874 - val_loss: 0.0579 - val_acc: 0.9145 9s - loss: 0.1068 -  - ETA: 8s - loss: 0.10 - ETA: 7s - loss: 0. - E\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1059 - acc: 0.4874 - val_loss: 0.0539 - val_acc: 0.9080\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1050 - acc: 0.4955 - val_loss: 0.0556 - val_acc: 0.9118\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1060 - acc: 0.4848 - val_loss: 0.0533 - val_acc: 0.9057 ETA: 5s - los - ETA: 3s - loss: 0. - ETA: 2s - loss: 0.1057 - ETA: 1s - los\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1030 - acc: 0.5024 - val_loss: 0.0531 - val_acc: 0.9125\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1060 - acc: 0.4860 - val_loss: 0.0539 - val_acc: 0.9135\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1056 - acc: 0.4865 - val_loss: 0.0556 - val_acc: 0.9155\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.1040 - acc: 0.4966 - val_loss: 0.0539 - val_acc: 0.9206\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1052 - acc: 0.4876 - val_loss: 0.0544 - val_acc: 0.9240\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1048 - acc: 0.4922 - val_loss: 0.0536 - val_acc: 0.9179: 0.1047\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1039 - acc: 0.4965 - val_loss: 0.0531 - val_acc: 0.9125\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1032 - acc: 0.5016 - val_loss: 0.0564 - val_acc: 0.9128\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1035 - acc: 0.4993 - val_loss: 0.0560 - val_acc: 0.9250\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1040 - acc: 0.4954 - val_loss: 0.0566 - val_acc: 0.9230\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1043 - acc: 0.4936 - val_loss: 0.0527 - val_acc: 0.9196\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1049 - acc: 0.4882 - val_loss: 0.0530 - val_acc: 0.9233\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1040 - acc: 0.4946 - val_loss: 0.0548 - val_acc: 0.9155\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1034 - acc: 0.4973 - val_loss: 0.0552 - val_acc: 0.9213\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 12s 2ms/step - loss: 0.1030 - acc: 0.5000 - val_loss: 0.0551 - val_acc: 0.9223\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 12s 2ms/step - loss: 0.1051 - acc: 0.4874 - val_loss: 0.0554 - val_acc: 0.9148TA: 6s - loss: 0.10 - ETA: 2s - loss:  - ETA: 1s - loss: 0.1049 - acc: 0.48 - ETA: 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e059556710>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 537        0         0        0                   0   \n",
      "SITTING                  0      400        69        0                   0   \n",
      "STANDING                 0      102       430        0                   0   \n",
      "WALKING                  0        0         0      479                  16   \n",
      "WALKING_DOWNSTAIRS       0        2         0        2                 414   \n",
      "WALKING_UPSTAIRS         0        0         0       11                  24   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             0  \n",
      "SITTING                           22  \n",
      "STANDING                           0  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 2  \n",
      "WALKING_UPSTAIRS                 436  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_349 (Conv1D)          (None, 126, 30)           840       \n",
      "_________________________________________________________________\n",
      "conv1d_350 (Conv1D)          (None, 124, 50)           4550      \n",
      "_________________________________________________________________\n",
      "conv1d_351 (Conv1D)          (None, 122, 100)          15100     \n",
      "_________________________________________________________________\n",
      "flatten_57 (Flatten)         (None, 12200)             0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 6)                 73206     \n",
      "_________________________________________________________________\n",
      "dropout_229 (Dropout)        (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 93,696\n",
      "Trainable params: 93,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(30, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(Conv1D(50, 3, activation='relu'))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1336 - acc: 0.4051 - val_loss: 0.0837 - val_acc: 0.6498\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1217 - acc: 0.4517 - val_loss: 0.0706 - val_acc: 0.8269\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1110 - acc: 0.4879 - val_loss: 0.0659 - val_acc: 0.8673\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1087 - acc: 0.4853 - val_loss: 0.0629 - val_acc: 0.8724\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1065 - acc: 0.4947 - val_loss: 0.0635 - val_acc: 0.8741\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 17s 2ms/step - loss: 0.1065 - acc: 0.4878 - val_loss: 0.0613 - val_acc: 0.8850\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 18s 2ms/step - loss: 0.1070 - acc: 0.4838 - val_loss: 0.0603 - val_acc: 0.8880\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.1065 - acc: 0.4853 - val_loss: 0.0580 - val_acc: 0.8972\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1056 - acc: 0.4905 - val_loss: 0.0572 - val_acc: 0.8938\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1034 - acc: 0.5015 - val_loss: 0.0569 - val_acc: 0.9040\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1059 - acc: 0.4845 - val_loss: 0.0569 - val_acc: 0.8968\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.1048 - acc: 0.4903 - val_loss: 0.0550 - val_acc: 0.9036\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1030 - acc: 0.5003 - val_loss: 0.0577 - val_acc: 0.9057\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 19s 3ms/step - loss: 0.1047 - acc: 0.4898 - val_loss: 0.0570 - val_acc: 0.9016\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 22s 3ms/step - loss: 0.1041 - acc: 0.4922 - val_loss: 0.0547 - val_acc: 0.9182\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.1039 - acc: 0.4936 - val_loss: 0.0557 - val_acc: 0.9070\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.1035 - acc: 0.4928 - val_loss: 0.0565 - val_acc: 0.9009\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 20s 3ms/step - loss: 0.1046 - acc: 0.4863 - val_loss: 0.0575 - val_acc: 0.9050\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 23s 3ms/step - loss: 0.1045 - acc: 0.4882 - val_loss: 0.0552 - val_acc: 0.9043\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1035 - acc: 0.4906 - val_loss: 0.0540 - val_acc: 0.91314s - loss: 0.103\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.1022 - acc: 0.4984 - val_loss: 0.0572 - val_acc: 0.9033\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1028 - acc: 0.4955 - val_loss: 0.0540 - val_acc: 0.9101\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 21s 3ms/step - loss: 0.1047 - acc: 0.4803 - val_loss: 0.0553 - val_acc: 0.9203\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1034 - acc: 0.4906 - val_loss: 0.0546 - val_acc: 0.9145\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1026 - acc: 0.4966 - val_loss: 0.0544 - val_acc: 0.9186\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1030 - acc: 0.4936 - val_loss: 0.0533 - val_acc: 0.9111\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1023 - acc: 0.4969 - val_loss: 0.0552 - val_acc: 0.9118\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 38s 5ms/step - loss: 0.1012 - acc: 0.5015 - val_loss: 0.0537 - val_acc: 0.9111\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1037 - acc: 0.4871 - val_loss: 0.0545 - val_acc: 0.9074: 0.1036\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 39s 5ms/step - loss: 0.1020 - acc: 0.4976 - val_loss: 0.0536 - val_acc: 0.9192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e074bc69b0>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      415        49        0                   0   \n",
      "STANDING                 0       75       455        0                   0   \n",
      "WALKING                  0        1         0      477                  12   \n",
      "WALKING_DOWNSTAIRS       0        0         0        1                 415   \n",
      "WALKING_UPSTAIRS         0        0         0       12                  22   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                           27  \n",
      "STANDING                           2  \n",
      "WALKING                            6  \n",
      "WALKING_DOWNSTAIRS                 4  \n",
      "WALKING_UPSTAIRS                 437  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_353 (Conv1D)          (None, 126, 100)          2800      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 42, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_59 (Flatten)         (None, 4200)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 6)                 25206     \n",
      "_________________________________________________________________\n",
      "dropout_231 (Dropout)        (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 28,006\n",
      "Trainable params: 28,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/heeryoncho/sensors2018cnnhar/blob/master/har/har_dyna_learn_model.py\n",
    "model = Sequential()\n",
    "model.add(Conv1D(100, 3, input_shape=(timesteps, input_dim), activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "adam = Adam(lr=0.0004, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "# Summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 41s 6ms/step - loss: 1.5143 - acc: 0.8411 - val_loss: 0.2502 - val_acc: 0.8933\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 1.5138 - acc: 0.8412 - val_loss: 0.1998 - val_acc: 0.9155\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.5682 - acc: 0.8396 - val_loss: 0.3520 - val_acc: 0.9094 1.5105 - acc: 0.84 - ETA: 5s - loss: 1.509 - ETA: 2s - loss: 1.548 - ETA: 1s - loss: 1.556 - ETA: 0s - loss: 1.5610 - acc: 0\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 1.6205 - acc: 0.8273 - val_loss: 0.2298 - val_acc: 0.9117\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 1.5085 - acc: 0.8448 - val_loss: 0.2064 - val_acc: 0.9188\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 1.5108 - acc: 0.8403 - val_loss: 0.2658 - val_acc: 0.8953\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 1.4995 - acc: 0.8410 - val_loss: 0.2054 - val_acc: 0.9177\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4761 - acc: 0.8591 - val_loss: 0.2081 - val_acc: 0.9169 - ETA: 0s - loss: 1.4773 - acc: 0.\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4699 - acc: 0.8465 - val_loss: 0.2351 - val_acc: 0.9066\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4414 - acc: 0.8562 - val_loss: 0.1858 - val_acc: 0.9314\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 1.4420 - acc: 0.8540 - val_loss: 0.1861 - val_acc: 0.9296\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4504 - acc: 0.8537 - val_loss: 0.1654 - val_acc: 0.9423\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 1.4442 - acc: 0.8499 - val_loss: 0.1583 - val_acc: 0.9467\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4577 - acc: 0.8439 - val_loss: 0.5166 - val_acc: 0.8663\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.6584 - acc: 0.8291 - val_loss: 0.1809 - val_acc: 0.9307\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4239 - acc: 0.8509 - val_loss: 0.1713 - val_acc: 0.9419\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 1.4503 - acc: 0.8508 - val_loss: 0.1771 - val_acc: 0.9372s: 1.4484 - acc: 0.8\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4538 - acc: 0.8523 - val_loss: 0.1616 - val_acc: 0.9491\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4067 - acc: 0.8510 - val_loss: 0.1552 - val_acc: 0.9493\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 1.4531 - acc: 0.8412 - val_loss: 0.1752 - val_acc: 0.9439oss: 1\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4786 - acc: 0.8389 - val_loss: 0.1575 - val_acc: 0.9500\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4124 - acc: 0.8419 - val_loss: 0.1493 - val_acc: 0.9553: 0s - loss: 1.4115 - a\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4439 - acc: 0.8403 - val_loss: 0.1469 - val_acc: 0.9578\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4133 - acc: 0.8394 - val_loss: 0.1438 - val_acc: 0.9589\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 1.4602 - acc: 0.8362 - val_loss: 0.1679 - val_acc: 0.9535 ETA: 3s - lo - ETA: 1s - \n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4282 - acc: 0.8362 - val_loss: 0.1535 - val_acc: 0.9559\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 1.4472 - acc: 0.8346 - val_loss: 0.1450 - val_acc: 0.9576\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 1.4629 - acc: 0.8333 - val_loss: 0.1553 - val_acc: 0.9585\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 1.4105 - acc: 0.8351 - val_loss: 0.1486 - val_acc: 0.9603\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 12s 2ms/step - loss: 1.3995 - acc: 0.8339 - val_loss: 0.1464 - val_acc: 0.9607A: 7s - ETA: 5s - loss: 1.4363 - acc -  - ETA: 2s - lo - ETA: 1s - loss: 1.4184 - acc:  - ETA: 0s - loss: 1.4100 - acc: 0 - ETA: 0s - loss: 1.4061 - ac\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e07e12e630>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      409        80        0                   0   \n",
      "STANDING                 0      100       430        0                   0   \n",
      "WALKING                  0        0         0      428                  49   \n",
      "WALKING_DOWNSTAIRS       0        0         0       12                 397   \n",
      "WALKING_UPSTAIRS         0        0         0        7                  35   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                            2  \n",
      "STANDING                           2  \n",
      "WALKING                           19  \n",
      "WALKING_DOWNSTAIRS                11  \n",
      "WALKING_UPSTAIRS                 429  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
